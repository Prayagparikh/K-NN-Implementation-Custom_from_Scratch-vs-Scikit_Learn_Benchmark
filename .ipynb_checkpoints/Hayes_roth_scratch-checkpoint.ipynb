{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f2a90576-4d85-48da-a639-4081768364ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import KFold\n",
    "from random import seed\n",
    "from random import randrange\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fc070350-a725-496d-99ff-8cd850aef981",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"./hayes+roth/hayes-roth.data.csv\")\n",
    "dataset_test = pd.read_csv(\"./hayes+roth/hayes-roth.test.csv\")\n",
    "dataset = dataset.mask(dataset == '')\n",
    "dataset_test = dataset_test.mask(dataset_test == '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d5d98fa4-e21c-4214-8fcf-3f691388f5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting dataset\n",
    "X_train = dataset.iloc[ : , :]\n",
    "y_train = dataset.iloc[ : , 5]\n",
    "X_test = dataset_test.iloc[ : , :]\n",
    "y_test = dataset_test.iloc[ : , 5]\n",
    "\n",
    "X_train = X_train.values.tolist()\n",
    "X_test = X_test.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc230072-dac9-406d-a8a7-cf5bb5fa42dd",
   "metadata": {},
   "source": [
    "## Full code for Hayes Roth Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2e2d0e5e-3bba-40b4-a4fe-2702ed685633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean Distances:\n",
      "Row 0: 2.0\n",
      "Row 1: 0.0\n",
      "Row 2: 1.4142135623730951\n",
      "Row 3: 3.1622776601683795\n",
      "Row 4: 2.0\n",
      "Row 5: 0.0\n",
      "Row 6: 0.0\n",
      "Row 7: 3.7416573867739413\n",
      "Row 8: 2.449489742783178\n",
      "Row 9: 2.449489742783178\n",
      "Row 10: 2.449489742783178\n",
      "Row 11: 2.23606797749979\n",
      "Row 12: 1.4142135623730951\n",
      "Row 13: 1.0\n",
      "Row 14: 4.123105625617661\n",
      "Row 15: 1.0\n",
      "Row 16: 2.23606797749979\n",
      "Row 17: 2.449489742783178\n",
      "Row 18: 2.449489742783178\n",
      "Row 19: 0.0\n",
      "Row 20: 1.7320508075688772\n",
      "Row 21: 2.449489742783178\n",
      "Row 22: 1.4142135623730951\n",
      "Row 23: 2.449489742783178\n",
      "Row 24: 2.449489742783178\n",
      "Row 25: 1.7320508075688772\n",
      "Row 26: 2.449489742783178\n",
      "Row 27: 1.0\n",
      "Row 28: 0.0\n",
      "Row 29: 2.449489742783178\n",
      "Row 30: 3.7416573867739413\n",
      "Row 31: 2.449489742783178\n",
      "Row 32: 2.449489742783178\n",
      "Row 33: 2.0\n",
      "Row 34: 3.1622776601683795\n",
      "Row 35: 1.0\n",
      "Row 36: 1.0\n",
      "Row 37: 1.7320508075688772\n",
      "Row 38: 2.23606797749979\n",
      "Row 39: 3.0\n",
      "Row 40: 1.7320508075688772\n",
      "Row 41: 2.23606797749979\n",
      "Row 42: 2.449489742783178\n",
      "Row 43: 2.449489742783178\n",
      "Row 44: 1.4142135623730951\n",
      "Row 45: 2.449489742783178\n",
      "Row 46: 2.0\n",
      "Row 47: 2.0\n",
      "Row 48: 1.7320508075688772\n",
      "Row 49: 3.0\n",
      "Row 50: 2.23606797749979\n",
      "Row 51: 2.23606797749979\n",
      "Row 52: 2.23606797749979\n",
      "Row 53: 1.4142135623730951\n",
      "Row 54: 2.0\n",
      "Row 55: 0.0\n",
      "Row 56: 1.7320508075688772\n",
      "Row 57: 1.4142135623730951\n",
      "Row 58: 2.449489742783178\n",
      "Row 59: 1.0\n",
      "Row 60: 1.4142135623730951\n",
      "Row 61: 2.23606797749979\n",
      "Row 62: 2.23606797749979\n",
      "Row 63: 2.449489742783178\n",
      "Row 64: 3.1622776601683795\n",
      "Row 65: 2.449489742783178\n",
      "Row 66: 1.0\n",
      "Row 67: 1.0\n",
      "Row 68: 3.0\n",
      "Row 69: 1.0\n",
      "Row 70: 1.0\n",
      "Row 71: 0.0\n",
      "Row 72: 0.0\n",
      "Row 73: 0.0\n",
      "Row 74: 2.449489742783178\n",
      "Row 75: 3.3166247903554\n",
      "Row 76: 1.4142135623730951\n",
      "Row 77: 3.605551275463989\n",
      "Row 78: 2.449489742783178\n",
      "Row 79: 1.4142135623730951\n",
      "Row 80: 1.7320508075688772\n",
      "Row 81: 1.0\n",
      "Row 82: 0.0\n",
      "Row 83: 2.449489742783178\n",
      "Row 84: 3.3166247903554\n",
      "Row 85: 2.0\n",
      "Row 86: 2.449489742783178\n",
      "Row 87: 2.449489742783178\n",
      "Row 88: 2.23606797749979\n",
      "Row 89: 2.23606797749979\n",
      "Row 90: 1.7320508075688772\n",
      "Row 91: 2.449489742783178\n",
      "Row 92: 2.449489742783178\n",
      "Row 93: 2.23606797749979\n",
      "Row 94: 2.0\n",
      "Row 95: 1.7320508075688772\n",
      "Row 96: 2.449489742783178\n",
      "Row 97: 1.4142135623730951\n",
      "Row 98: 2.23606797749979\n",
      "Row 99: 2.449489742783178\n",
      "Row 100: 2.449489742783178\n",
      "Row 101: 1.0\n",
      "Row 102: 2.23606797749979\n",
      "Row 103: 2.0\n",
      "Row 104: 1.7320508075688772\n",
      "Row 105: 1.7320508075688772\n",
      "Row 106: 2.449489742783178\n",
      "Row 107: 3.0\n",
      "Row 108: 3.3166247903554\n",
      "Row 109: 2.449489742783178\n",
      "Row 110: 2.449489742783178\n",
      "Row 111: 1.0\n",
      "Row 112: 2.449489742783178\n",
      "Row 113: 1.4142135623730951\n",
      "Row 114: 2.0\n",
      "Row 115: 3.4641016151377544\n",
      "Row 116: 2.449489742783178\n",
      "Row 117: 1.4142135623730951\n",
      "Row 118: 2.23606797749979\n",
      "Row 119: 2.23606797749979\n",
      "Row 120: 1.7320508075688772\n",
      "Row 121: 2.8284271247461903\n",
      "Row 122: 1.0\n",
      "Row 123: 2.449489742783178\n",
      "Row 124: 3.0\n",
      "Row 125: 2.0\n",
      "Row 126: 3.7416573867739413\n",
      "Row 127: 1.4142135623730951\n",
      "Row 128: 1.4142135623730951\n",
      "Row 129: 2.23606797749979\n",
      "Row 130: 1.7320508075688772\n",
      "Row 131: 2.0\n",
      "\n",
      "Indices of the Nearest Neighbors:\n",
      "[28 73 72 82 71]\n",
      "\n",
      "Classes of the Nearest Neighbors:\n",
      "Row 28: [30, 1, 1, 3, 2, 1] - Class: 1\n",
      "Row 73: [119, 3, 1, 3, 2, 1] - Class: 1\n",
      "Row 72: [41, 1, 1, 3, 2, 2] - Class: 2\n",
      "Row 82: [120, 1, 1, 3, 2, 1] - Class: 1\n",
      "Row 71: [2, 2, 1, 3, 2, 2] - Class: 2\n",
      "************************ FINAL PREDICTION OUTPUT ************************\n",
      "New Observation: [55, 3, 1, 3, 2]\n",
      "Predicted class: 1\n"
     ]
    }
   ],
   "source": [
    "# PLEASE REFER: Details regarding Hayes Roth Dataset and how it is used here is in 'Doc file'\n",
    "\n",
    "def euclidean_distance(row1, row2):\n",
    "    distance = 0.0\n",
    "    for i in range(2, len(row2)-1):\n",
    "        distance += (row1[i] - row2[i])**2\n",
    "    return sqrt(distance)\n",
    "\n",
    "def get_neighbors(X_train, test_row, k):\n",
    "    distance = list()\n",
    "    data = []\n",
    "    \n",
    "    for i in X_train:\n",
    "        dist = euclidean_distance(test_row, i)\n",
    "        distance.append(dist)\n",
    "        data.append(i)\n",
    "        \n",
    "    distance = np.array(distance)\n",
    "    data = np.array(data, dtype=object)\n",
    "    # Find the index of min distance and sorting accordingly\n",
    "    index_dist = distance.argsort()\n",
    "    # We arrange our data according to index\n",
    "    data = data[index_dist]\n",
    "    # slicing k neighbors from data[]\n",
    "    neighbors = data[:k]\n",
    "    return neighbors\n",
    "\n",
    "def predict_classification(train, test_row, k):\n",
    "    neighbors = get_neighbors(train, test_row, k)\n",
    "    classes = []\n",
    "    for i in neighbors:\n",
    "        classes.append(i[-1])\n",
    "    prediction = max(classes, key=classes.count)\n",
    "    return prediction\n",
    "\n",
    "new_observation_row = [55, 3, 1, 3, 2]\n",
    "# Large k-value\n",
    "large_k = int(sqrt(len(X_train)))\n",
    "if large_k%2==1 : large_k+=1\n",
    "\n",
    "# Calculate the distances between new_observation_row and each row in X_train\n",
    "distances = []\n",
    "for i in range(len(X_train)):\n",
    "    distance = euclidean_distance(new_observation_row, X_train[i])\n",
    "    distances.append(distance)\n",
    "\n",
    "# Find the indices of the k nearest neighbors\n",
    "nearest_indices = np.argsort(distances)[:5]\n",
    "\n",
    "# Print the calculated distances for the new observation row\n",
    "print(\"Euclidean Distances:\")\n",
    "for idx in range(len(distances)):\n",
    "    print(f\"Row {idx}: {distances[idx]}\")\n",
    "\n",
    "# Print the indices of the k nearest neighbors\n",
    "print(\"\\nIndices of the Nearest Neighbors:\")\n",
    "print(nearest_indices)\n",
    "\n",
    "# Print the classes of the nearest neighbors for verification\n",
    "print(\"\\nClasses of the Nearest Neighbors:\")\n",
    "for idx in nearest_indices:\n",
    "    print(f\"Row {idx}: {X_train[idx]} - Class: {y_train[idx]}\")\n",
    "\n",
    "prediction = predict_classification(X_train, new_observation_row, 5)\n",
    "print('************************ FINAL PREDICTION OUTPUT ************************')\n",
    "print('New Observation:', new_observation_row)\n",
    "print('Predicted class:', prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9649eaeb-bef5-496a-96b5-8a516459dda0",
   "metadata": {},
   "source": [
    "## Using 10-Fold Cross Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "af1ad07b-1c3f-4f95-816a-47622b8eeccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************ CROSS-VALIDATION RESULTS ************************\n",
      "Accuracy Scores: [38.46153846153847, 38.46153846153847, 23.076923076923077, 38.46153846153847, 46.15384615384615, 61.53846153846154, 38.46153846153847, 23.076923076923077, 30.76923076923077, 61.53846153846154]\n",
      "Average Accuracy: 40.0000\n"
     ]
    }
   ],
   "source": [
    "seed(20)\n",
    "n_folds = 10\n",
    "k = 3\n",
    "\n",
    "def cross_validation_split(dataset, n_folds):\n",
    "    dataset_split = []\n",
    "    dataset_copy = copy.deepcopy(dataset)\n",
    "    fold_size = int(len(dataset) / n_folds)\n",
    "    for _ in range(n_folds):\n",
    "        fold = []\n",
    "        while len(fold) < fold_size:\n",
    "            index = randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        dataset_split.append(fold)\n",
    "    return dataset_split\n",
    "\n",
    "def evaluate_algorithm(dataset, n_folds, k):\n",
    "    folds = cross_validation_split(dataset, n_folds)\n",
    "    scores = []\n",
    "    for fold in folds:\n",
    "        train_set = list(folds)\n",
    "        train_set.remove(fold)\n",
    "        train_set = sum(train_set, [])\n",
    "        test_set = []\n",
    "        for row in fold:\n",
    "            row_copy = list(row)\n",
    "            test_set.append(row_copy)\n",
    "            row_copy[-1] = None  # remove the class label for testing\n",
    "        predictions = []\n",
    "        for row in test_set:\n",
    "            output = predict_classification(train_set, row, k)\n",
    "            predictions.append(output)\n",
    "        actual = [row[-1] for row in fold]\n",
    "        correct = sum(1 for i in range(len(actual)) if actual[i] == predictions[i])\n",
    "        accuracy = (correct / float(len(actual))) * 100.0\n",
    "        scores.append(accuracy)\n",
    "    return scores\n",
    "\n",
    "# Splitting dataset\n",
    "dataset = list(zip(X_train, y_train))\n",
    "dataset_test = list(zip(X_test, y_test))\n",
    "\n",
    "# Evaluating the algorithm using cross-validation\n",
    "scores = evaluate_algorithm(dataset, n_folds, k)\n",
    "\n",
    "print('************************ CROSS-VALIDATION RESULTS ************************')\n",
    "print('Accuracy Scores:', scores)\n",
    "print('Average Accuracy: {:.4f}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d3d267-3c32-46b3-8804-541bd533926e",
   "metadata": {},
   "source": [
    "## Measuring Training and Testing dataset accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "417f2ac4-b9f5-4eba-a32e-82a190283b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 87.12121%\n",
      "Testing Accuracy: 78.57143%\n"
     ]
    }
   ],
   "source": [
    "train_correct_predictions = 0\n",
    "for i in range(len(y_train)):\n",
    "    prediction = predict_classification(X_train, X_train[i], 3)\n",
    "    if prediction == y_train[i]:\n",
    "        train_correct_predictions += 1\n",
    "\n",
    "train_accuracy = (train_correct_predictions / len(y_train)) * 100\n",
    "\n",
    "test_correct_predictions = 0\n",
    "for i in range(len(y_test)):\n",
    "    prediction = predict_classification(X_test, X_test[i], 3)\n",
    "    if prediction == y_test[i]:\n",
    "        test_correct_predictions += 1\n",
    "\n",
    "test_accuracy = (test_correct_predictions / len(y_test)) * 100\n",
    "\n",
    "# Print accuracies\n",
    "print(f'Training Accuracy: {train_accuracy:.5f}%')\n",
    "print(f'Testing Accuracy: {test_accuracy:.5f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f8a02c-ee7d-4be9-8348-e7e04ac39d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 1: Calculate euclidean distance\n",
    "# def euclidean_distance(row1, row2):\n",
    "#     distance = 0.0\n",
    "#     for i in range(2, len(row1)-1):\n",
    "#         distance += (row1[i] - row2[i])**2\n",
    "#     return sqrt(distance)\n",
    "\n",
    "\n",
    "# sample = [\n",
    "#     [92, 2, 1, 1, 2, 1],\n",
    "#     [10, 2, 1, 3, 2, 2],\n",
    "#     [83, 3, 1, 4, 1, 3],\n",
    "#     [61, 2, 4, 2, 2, 3],\n",
    "#     [107, 1, 1, 3, 4, 3]\n",
    "# ]\n",
    "\n",
    "# row1 = sample[0]\n",
    "# for i in range(len(sample)):\n",
    "#     row2 = sample[i]\n",
    "#     distance = euclidean_distance(row1, row2)\n",
    "#     print(f\"Euclidean Distance between {row1} and {row2}: {distance}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e1fe92-8451-4595-93ef-cd8469a6d431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 2: Finding neighbors\n",
    "\n",
    "# def get_neighbors(X_train, test_row, k):\n",
    "#     distance = list()\n",
    "#     data = []\n",
    "#     for i in X_train:\n",
    "#         dist = euclidean_distance(test_row, i)\n",
    "#         distance.append(dist)\n",
    "#         data.append(i)\n",
    "#     distance = np.array(distance)\n",
    "#     data = np.array(data)\n",
    "#     # Find the index of min distance and sorting accordingly\n",
    "#     index_dist = distance.argsort()\n",
    "#     # We arrange our data according to index\n",
    "#     data = data[index_dist]\n",
    "#     # slicing k neighbors from data[]\n",
    "#     neighbors = data[:k]\n",
    "    \n",
    "#     return neighbors\n",
    "\n",
    "# dataset = [\n",
    "#     [92, 2, 1, 1, 2, 1],\n",
    "#     [10, 2, 1, 3, 2, 2],\n",
    "#     [83, 3, 1, 4, 1, 3],\n",
    "#     [61, 2, 4, 2, 2, 3],\n",
    "#     [107, 1, 1, 3, 4, 3]\n",
    "# ]\n",
    "# # Choosing k: Source: Youtube link in references, and remaining details in Word file\n",
    "# k = int(sqrt(len(dataset)))\n",
    "# if k%2==1 : k+=1\n",
    "# print('k:', k)\n",
    "# neighbors = get_neighbors(dataset, dataset[0], k)\n",
    "# for neighbor in neighbors:\n",
    "#  print(neighbor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c438be8-58fb-4d7c-9613-3e46c23a1875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 3: Making our prediction\n",
    "\n",
    "# def predict_classification(train, test_row, k):\n",
    "#     neighbors = get_neighbors(train, test_row, k)\n",
    "#     classes = []\n",
    "#     for i in neighbors:\n",
    "#         classes.append(i[-1])\n",
    "#     prediction = max(classes, key=classes.count)\n",
    "#     return prediction\n",
    "\n",
    "# dataset = [\n",
    "#     [92, 2, 1, 1, 2, 1],\n",
    "#     [10, 2, 1, 3, 2, 2],\n",
    "#     [83, 3, 1, 4, 1, 3],\n",
    "#     [61, 2, 4, 2, 2, 3],\n",
    "#     [107, 1, 1, 3, 4, 3]\n",
    "# ]\n",
    "# prediction = predict_classification(dataset, dataset[0], 2)\n",
    "# print('Predicted class:', prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675247d4-386f-4734-a476-b2e340f934f4",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607c341d-3a1c-4487-9d94-7bb118eb4298",
   "metadata": {},
   "source": [
    "1. https://machinelearningmastery.com/tutorial-to-implement-k-nearest-neighbors-in-python-from-scratch/\n",
    "2. Youtube Link: \n",
    "3. nan: https://sparkbyexamples.com/pandas/pandas-replace-blank-values-with-nan/?expand_article=1\n",
    "4. https://www.linkedin.com/pulse/k-nearest-neighbor-algorithm-from-scratchwithout-library-ritika-yadav/\n",
    "5. K-Fold implementation: https://www.datacamp.com/tutorial/k-nearest-neighbor-classification-scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9440f001-77df-40ef-a496-6a54eb5b9a45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
